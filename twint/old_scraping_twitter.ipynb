{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T10:38:33.019340Z",
     "start_time": "2020-12-03T10:38:23.399455Z"
    }
   },
   "outputs": [],
   "source": [
    "import twint\n",
    "import nest_asyncio\n",
    "import tqdm\n",
    "import datetime\n",
    "from multiprocessing import Process\n",
    "import os\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T10:38:33.028359Z",
     "start_time": "2020-12-03T10:38:33.021857Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FILE = \"data_test/\"\n",
    "if not os.path.isdir(DATA_FILE):\n",
    "        os.mkdir(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T10:38:33.054695Z",
     "start_time": "2020-12-03T10:38:33.035485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abu_sayyaf', 'afghanistan', 'agro', 'al-qaeda', 'al-qaeda_in_the_arabian_peninsula', 'al-qaeda_in_the_islamic_maghreb', 'al-shabaab', 'ammonium_nitrate', 'attack', 'biological_weapon', 'car_bomb', 'chemical_weapon', 'conventional_weapon', 'dirty_bomb', 'eco-terrorism', 'environmental_terrorism', 'euskadi_ta_askatasuna', 'extremism', 'farc', 'fundamentalism', 'hamas', 'hezbollah', 'improvised_explosive_device', 'iran', 'iraq', 'irish_republican_army', 'islamist', 'jihad', 'nationalism', 'nigeria', 'nuclear', 'nuclear_enrichment', 'pakistan', 'palestine_liberation_front', 'pirates', 'plo', 'political_radicalism', 'recruitment', 'somalia', 'suicide_attack', 'suicide_bomber', 'taliban', 'tamil_tigers', 'tehrik-i-taliban_pakistan', 'terror', 'terrorism', 'weapons-grade', 'yemen']\n"
     ]
    }
   ],
   "source": [
    "search_terms = []\n",
    "with open('config/search-terms.txt') as f:\n",
    "    lines = f.read().splitlines()\n",
    "search_terms = lines\n",
    "print(search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T10:38:38.225522Z",
     "start_time": "2020-12-03T10:38:38.216796Z"
    }
   },
   "outputs": [],
   "source": [
    "short_terms = ['abu_sayyaf', 'al-qaeda', 'al-qaeda_in_the_arabian_peninsula', 'al-qaeda_in_the_islamic_maghreb', 'al-shabaab', 'ammonium_nitrate', 'biological_weapon', 'car_bomb', 'chemical_weapon', 'conventional_weapon', 'dirty_bomb', 'eco-terrorism', 'environmental_terrorism', 'euskadi_ta_askatasuna', 'extremism', 'farc', 'fundamentalism', 'hezbollah', 'improvised_explosive_device', 'irish_republican_army', 'jihad', 'nuclear_enrichment', 'palestine_liberation_front', 'political_radicalism', 'suicide_attack', 'suicide_bomber', 'taliban', 'tamil_tigers', 'tehrik-i-taliban_pakistan', 'weapons-grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T10:38:38.399030Z",
     "start_time": "2020-12-03T10:38:38.393731Z"
    }
   },
   "outputs": [],
   "source": [
    "long_terms = ['afghanistan', 'hamas', 'iran', 'iraq', 'islamist', 'nationalism', 'nigeria', 'pakistan', 'somalia', 'terrorism', 'yemen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T10:38:38.614040Z",
     "start_time": "2020-12-03T10:38:38.607885Z"
    }
   },
   "outputs": [],
   "source": [
    "black_list = ['agro', 'attack', 'nuclear', 'pirates', 'plo', 'recruitment', 'terror']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T10:38:38.864347Z",
     "start_time": "2020-12-03T10:38:38.857362Z"
    }
   },
   "outputs": [],
   "source": [
    "concatenated = short_terms+long_terms+black_list\n",
    "for elem in search_terms:\n",
    "    if elem not in concatenated :\n",
    "        print(\"The two lists differ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T10:38:40.137456Z",
     "start_time": "2020-12-03T10:38:40.094872Z"
    }
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "from time import sleep\n",
    "\n",
    "def distribute_scrap(term, since, until):\n",
    "    mid_string = since[:8] + '15'\n",
    "    mid_string2 = since[:8] + '16'\n",
    "    \n",
    "    mid_date = (int(since[8:]) + int(until[8:])) // 2\n",
    "    mid_string =  since[:8] + f\"{mid_date:02d}\"\n",
    "    mid_string2 = since[:8] + f\"{mid_date + 1:02d}\"\n",
    "    t1 = threading.Thread(target=Scrap, args=(term, since, mid_string))\n",
    "    t1.start()\n",
    "    print(term, ' from ', since, ' to ', mid_string)\n",
    "    sleep(15)\n",
    "    t2 = threading.Thread(target=Scrap, args=(term, mid_string2, until))\n",
    "    t2.start()\n",
    "    print(term, ' from ', mid_string2, ' to ', until)\n",
    "\n",
    "def Scrap(term, since, until):\n",
    "    print(term, ' from ', since, ' to ', until)\n",
    "    c = twint.Config()\n",
    "    c.Search = term\n",
    "    c.Since = since\n",
    "    c.Until = until\n",
    "    folder = DATA_FILE+term\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "    c.Output = folder+'/'+since+'-'+term+\".csv\"\n",
    "    c.Hide_output = True\n",
    "    c.Store_csv = True\n",
    "    try:\n",
    "        twint.run.Search(c)\n",
    "    except:\n",
    "        print(f\"******************** Exception {term} {since} {until}\")\n",
    "        Scrap(term, since, until)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T10:40:04.353765Z",
     "start_time": "2020-12-03T10:40:04.343384Z"
    }
   },
   "outputs": [],
   "source": [
    "from time_partition import create_keyword_partition\n",
    "\n",
    "short_terms = ['abu_sayyaf', 'al-qaeda', 'al-qaeda_in_the_arabian_peninsula', 'al-qaeda_in_the_islamic_maghreb', 'al-shabaab', 'ammonium_nitrate', 'biological_weapon', 'car_bomb', 'chemical_weapon', 'conventional_weapon', 'dirty_bomb', 'eco-terrorism', 'environmental_terrorism', 'euskadi_ta_askatasuna', 'extremism', 'farc', 'fundamentalism', 'hezbollah', 'improvised_explosive_device', 'irish_republican_army', 'jihad', 'nuclear_enrichment', 'palestine_liberation_front', 'political_radicalism', 'suicide_attack', 'suicide_bomber', 'taliban', 'tamil_tigers', 'tehrik-i-taliban_pakistan', 'weapons-grade']\n",
    "short_terms = short_terms[1:]\n",
    "work = []\n",
    "\n",
    "for keyword in ['taliban']:\n",
    "    work+=create_keyword_partition(keyword, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T10:40:38.819791Z",
     "start_time": "2020-12-03T10:40:38.814534Z"
    }
   },
   "outputs": [],
   "source": [
    "work =work[132:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T10:40:40.103634Z",
     "start_time": "2020-12-03T10:40:40.097986Z"
    }
   },
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# import multiprocessing\n",
    "\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "# results = Parallel(n_jobs=20)(delayed(distribute_scrap)(keyword_data[0], keyword_data[1], keyword_data[2]) for keyword_data in work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-03T10:40:42.873Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taliban  from  2014-10-01  to  2014-10-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "taliban  from  2014-10-08  to  2014-10-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "taliban  from  2014-10-15  to  2014-10-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "taliban  from  2014-10-22  to  2014-10-31\n",
      "******************** Exception taliban 2014-10-22 2014-10-31\n",
      "taliban  from  2014-10-22  to  2014-10-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:SSL error in data received\n",
      "protocol: <asyncio.sslproto.SSLProtocol object at 0x7fab7d2767f0>\n",
      "transport: <_SelectorSocketTransport fd=64 read=polling write=<idle, bufsize=0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/twint/get.py\", line 168, in Response\n",
      "    resp = await response.text()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/aiohttp/client_reqrep.py\", line 1076, in text\n",
      "    await self.read()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/aiohttp/client_reqrep.py\", line 1032, in read\n",
      "    self._body = await self.content.read()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/aiohttp/streams.py\", line 371, in read\n",
      "    block = await self.readany()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/aiohttp/streams.py\", line 393, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/aiohttp/streams.py\", line 307, in _wait\n",
      "    await waiter\n",
      "  File \"/Applications/anaconda3/lib/python3.7/asyncio/futures.py\", line 260, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"/Applications/anaconda3/lib/python3.7/asyncio/tasks.py\", line 292, in __wakeup\n",
      "    future.result()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/asyncio/futures.py\", line 173, in result\n",
      "    raise CancelledError\n",
      "concurrent.futures._base.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-8-6d5b0d114c76>\", line 32, in Scrap\n",
      "    twint.run.Search(c)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/twint/run.py\", line 410, in Search\n",
      "    run(config, callback)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/twint/run.py\", line 329, in run\n",
      "    get_event_loop().run_until_complete(Twint(config).main(callback))\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/nest_asyncio.py\", line 95, in run_until_complete\n",
      "    return f.result()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/asyncio/futures.py\", line 178, in result\n",
      "    raise self._exception\n",
      "  File \"/Applications/anaconda3/lib/python3.7/asyncio/tasks.py\", line 225, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/twint/run.py\", line 235, in main\n",
      "    await task\n",
      "  File \"/Applications/anaconda3/lib/python3.7/asyncio/futures.py\", line 260, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"/Applications/anaconda3/lib/python3.7/asyncio/tasks.py\", line 292, in __wakeup\n",
      "    future.result()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/asyncio/futures.py\", line 178, in result\n",
      "    raise self._exception\n",
      "  File \"/Applications/anaconda3/lib/python3.7/asyncio/tasks.py\", line 223, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/twint/run.py\", line 262, in run\n",
      "    await self.tweets()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/twint/run.py\", line 217, in tweets\n",
      "    await self.Feed()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/twint/run.py\", line 62, in Feed\n",
      "    response = await get.RequestUrl(self.config, self.init)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/twint/get.py\", line 135, in RequestUrl\n",
      "    response = await Request(_url, params=params, connector=_connector, headers=_headers)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/twint/get.py\", line 161, in Request\n",
      "    return await Response(session, _url, params)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/twint/get.py\", line 171, in Response\n",
      "    return resp\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/async_timeout/__init__.py\", line 45, in __exit__\n",
      "    self._do_exit(exc_type)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/async_timeout/__init__.py\", line 92, in _do_exit\n",
      "    raise asyncio.TimeoutError\n",
      "concurrent.futures._base.TimeoutError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/asyncio/sslproto.py\", line 526, in data_received\n",
      "    ssldata, appdata = self._sslpipe.feed_ssldata(data)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/asyncio/sslproto.py\", line 207, in feed_ssldata\n",
      "    self._sslobj.unwrap()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/ssl.py\", line 767, in unwrap\n",
      "    return self._sslobj.shutdown()\n",
      "ssl.SSLError: [SSL: KRB5_S_INIT] application data after close notify (_ssl.c:2592)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "taliban  from  2014-11-01  to  2014-11-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "taliban  from  2014-11-08  to  2014-11-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "taliban  from  2014-11-15  to  2014-11-21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "taliban  from  2014-11-22  to  2014-11-30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "taliban  from  2014-12-01  to  2014-12-07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "taliban  from  2014-12-08  to  2014-12-14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "taliban  from  2014-12-15  to  2014-12-21\n"
     ]
    }
   ],
   "source": [
    "[Scrap(keyword_data[0], keyword_data[1], keyword_data[2]) for keyword_data in work]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
